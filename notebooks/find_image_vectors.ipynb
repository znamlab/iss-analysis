{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import imageio.v2 as imageio\n",
    "import vedo\n",
    "vedo.settings.default_backend= 'vtk'\n",
    "from vedo import Plane\n",
    "import brainrender\n",
    "from brainrender import Scene\n",
    "from brainglobe_atlasapi import BrainGlobeAtlas\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from pathlib import Path\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "from myterial import orange\n",
    "from rich import print\n",
    "\n",
    "from brainrender import Scene\n",
    "from brainrender.actors import Points\n",
    "from matplotlib import colors as mcolors\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "data_path = Path(\"C:/Microscope_images/processed/becalia_rabies_barseq/BRAC8498.3e/ara_spots\")\n",
    "ara_barcode_spots = pd.read_pickle(data_path / \"ara_barcode_spots.pkl\")\n",
    "ara_starters = pd.read_pickle(data_path / \"ara_starter_cells.pkl\")\n",
    "\n",
    "\n",
    "def read_in_BrainJ_cells(cells, regions, acronyms, not_in=None):\n",
    "    if len(regions) > 0:\n",
    "        cells = cells[cells['area_id'].isin(regions)]\n",
    "    if len(acronyms) > 0:\n",
    "        cells = cells[cells['area_acronym'].isin(acronyms)]\n",
    "    if not_in is not None:\n",
    "        cells = cells[~cells['area_acronym'].isin(not_in)]\n",
    "    Z = cells['ara_z'].tolist()\n",
    "    Y = cells['ara_y'].tolist()\n",
    "    X = cells['ara_x'].tolist()\n",
    "    \n",
    "    AtlasRes = 1000\n",
    "    X = [element * AtlasRes for element in X]\n",
    "    Y = [element * AtlasRes for element in Y]\n",
    "    Z = [element * AtlasRes for element in Z]\n",
    "    \n",
    "    if len(X) == 0:\n",
    "        return np.empty((0, 3))\n",
    "    \n",
    "    pts = [[x, y, z] for x, y, z in zip(X, Y, Z)]\n",
    "    return np.vstack(pts)\n",
    "\n",
    "def get_cycled_colors(n):\n",
    "    colors = list(mcolors.CSS4_COLORS.keys())\n",
    "    random.shuffle(colors)\n",
    "    return [colors[i % len(colors)] for i in range(n)]\n",
    "\n",
    "# Get unique barcodes present in both DataFrames\n",
    "common_barcodes = set(ara_barcode_spots['barcode'].unique()) & set(ara_starters['main_barcode'].unique())\n",
    "\n",
    "# Filter DataFrames to only include common barcodes\n",
    "ara_barcode_spots = ara_barcode_spots[ara_barcode_spots['barcode'].isin(common_barcodes)]\n",
    "ara_starters = ara_starters[ara_starters['main_barcode'].isin(common_barcodes)]\n",
    "\n",
    "# Function to render specific barcodes\n",
    "def render_selected_barcodes(selected_barcodes=None):\n",
    "    if selected_barcodes is None:\n",
    "        # Get all barcodes\n",
    "        selected_barcodes = common_barcodes\n",
    "    elif type(selected_barcodes) == int:\n",
    "        selected_barcodes = set(itertools.islice(common_barcodes, selected_barcodes))\n",
    "    unique_barcodes = list(set(selected_barcodes) & common_barcodes)\n",
    "    colors = get_cycled_colors(len(unique_barcodes))\n",
    "    barcode_to_color = dict(zip(unique_barcodes, colors))\n",
    "\n",
    "    # Group cells by barcode and color\n",
    "    for barcode in tqdm(unique_barcodes, desc=\"Processing barcodes\", unit=\"barcode\"):\n",
    "        # Get points for current barcode\n",
    "        rabies_cells = read_in_BrainJ_cells(\n",
    "            ara_starters[(ara_starters[\"starter\"]==False) & (ara_starters[\"main_barcode\"]==barcode)],\n",
    "            [],\n",
    "            [],\n",
    "            [\"outside\"]\n",
    "        )\n",
    "        \n",
    "        starter_cells = read_in_BrainJ_cells(\n",
    "            ara_starters[(ara_starters[\"starter\"]==True) & (ara_starters[\"main_barcode\"]==barcode)],\n",
    "            [],\n",
    "            [],\n",
    "            [\"outside\"]\n",
    "        )\n",
    "        \n",
    "        rabies_spots = read_in_BrainJ_cells(\n",
    "            ara_barcode_spots[ara_barcode_spots[\"barcode\"]==barcode],\n",
    "            [],\n",
    "            [],\n",
    "            [\"outside\"]\n",
    "        )\n",
    "\n",
    "        color = barcode_to_color[barcode]\n",
    "\n",
    "        if rabies_cells.size > 0:\n",
    "            scene.add(Points(\n",
    "                rabies_cells,\n",
    "                name=f\"rabies_cells_{barcode}\",\n",
    "                colors=color,\n",
    "                alpha=0.2,\n",
    "                radius=10\n",
    "            ))\n",
    "        if starter_cells.size > 0:\n",
    "            scene.add(Points(\n",
    "                starter_cells,\n",
    "                name=f\"starter_cells_{barcode}\",\n",
    "                colors=color,\n",
    "                alpha=0.4,\n",
    "                radius=20\n",
    "            ))\n",
    "        if rabies_spots.size > 0:\n",
    "            scene.add(Points(\n",
    "                rabies_spots,\n",
    "                name=f\"rabies_spots_{barcode}\",\n",
    "                colors=color,\n",
    "                alpha=1,\n",
    "                radius=2\n",
    "            ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "\n",
    "def generate_shades(base_color, num_shades):\n",
    "    base_rgb = mcolors.to_rgb(base_color)\n",
    "    # Adjust the range of alpha values to create a more extreme gradient\n",
    "    return [mcolors.to_hex((base_rgb[0] * alpha, base_rgb[1] * alpha, base_rgb[2] * alpha)) for alpha in np.linspace(1, 0.1, num_shades)]\n",
    "\n",
    "# Define the broad areas and their base colors\n",
    "large_actors = {\n",
    "    \"AUDpo\" : \"brown\",\n",
    "    \"VISp\" : \"blue\",\n",
    "    \"VISpl\" : \"lightgreen\",\n",
    "    \"VISl\" : \"mediumspringgreen\",\n",
    "    \"VISal\" : \"lime\",\n",
    "    \"VISpm\" : \"deepskyblue\",\n",
    "    \"VISli\" : \"cyan\",\n",
    "    \"RSP\" : \"deeppink\",\n",
    "    \"TEa\" : \"gold\",\n",
    "    'TH' : \"blueviolet\",\n",
    "    \"AUDd\" : \"yellow\",\n",
    "    \"AUDv\" : \"sandybrown\",\n",
    "    \"AUDp\" : \"orange\",\n",
    "}\n",
    "\n",
    "# Sub-areas that need to be shaded\n",
    "infected_areas = {   \n",
    "    ### Auditory primary\n",
    "    'AUDp1': \"AUDp\",\n",
    "    'AUDp2/3': \"AUDp\",\n",
    "    'AUDp4': \"AUDp\",\n",
    "    'AUDp5': \"AUDp\",\n",
    "    'AUDp6a': \"AUDp\",\n",
    "    'AUDp6b': \"AUDp\",\n",
    "    ### Auditory posterior\n",
    "    'AUDpo1': \"AUDpo\",\n",
    "    'AUDpo2/3': \"AUDpo\",\n",
    "    'AUDpo4': \"AUDpo\",\n",
    "    'AUDpo5': \"AUDpo\",\n",
    "    'AUDpo6a': \"AUDpo\",\n",
    "    'AUDpo6b': \"AUDpo\",\n",
    "    ### Auditory ventral\n",
    "    'AUDv2/3': \"AUDv\",\n",
    "    'AUDv4': \"AUDv\",\n",
    "    'AUDv5': \"AUDv\",\n",
    "    'AUDv6a': \"AUDv\",\n",
    "    'AUDv6b': \"AUDv\",\n",
    "    ### Thalamus\n",
    "    'IGL': \"TH\",\n",
    "    \"LGd-ip\" : \"TH\",\n",
    "    \"LGd-sh\" : \"TH\",\n",
    "    'LGd-co': \"TH\",\n",
    "    'MG': \"TH\",\n",
    "    'MGd': \"TH\",\n",
    "    'MGv': \"TH\",\n",
    "    \"LAT\" : \"TH\",\n",
    "    'IntG': \"TH\",\n",
    "    'LGd': \"TH\",\n",
    "    'LGv': \"TH\",\n",
    "    \"VENT\" : \"TH\",\n",
    "    \"PP\" : \"TH\",\n",
    "    \"PIL\" : \"TH\",\n",
    "    \"VPM\" : \"TH\",\n",
    "    \"VPMpc\" : \"TH\",\n",
    "    \"VM\" : \"TH\",\n",
    "    \"POL\" : \"TH\",\n",
    "    ### Retrosplenial lateral agranular\n",
    "    'RSPagl1': \"RSP\",\n",
    "    'RSPagl2/3': \"RSP\",\n",
    "    'RSPagl5': \"RSP\",\n",
    "    'RSPagl6a': \"RSP\",\n",
    "    'RSPagl6b': \"RSP\",\n",
    "    ### Retrosplenial dorsal\n",
    "    'RSPd1': \"RSP\",\n",
    "    'RSPd2/3': \"RSP\",\n",
    "    'RSPd5': \"RSP\",\n",
    "    'RSPd6a': \"RSP\",\n",
    "    'RSPd6b': \"RSP\",\n",
    "    ### Retrosplenial ventral\n",
    "    'RSPv1': \"RSP\",\n",
    "    'RSPv2/3': \"RSP\",\n",
    "    'RSPv5': \"RSP\",\n",
    "    'RSPv6a': \"RSP\",\n",
    "    ### Visual antero-lateral\n",
    "    'VISal1': \"VISal\",\n",
    "    'VISal2/3': \"VISal\",\n",
    "    'VISal4': \"VISal\",\n",
    "    'VISal5': \"VISal\",\n",
    "    'VISal6a': \"VISal\",\n",
    "    'VISal6b': \"VISal\",\n",
    "    ### Visual lateral\n",
    "    'VISl1': \"VISl\",\n",
    "    'VISl2/3': \"VISl\",\n",
    "    'VISl4': \"VISl\",\n",
    "    'VISl5': \"VISl\",\n",
    "    'VISl6a': \"VISl\",\n",
    "    'VISl6b': \"VISl\",\n",
    "    ### Visual laterointermediate\n",
    "    'VISli1': \"VISli\",\n",
    "    'VISli2/3': \"VISli\",\n",
    "    'VISli4': \"VISli\",\n",
    "    'VISli5': \"VISli\",\n",
    "    'VISli6a': \"VISli\",\n",
    "    'VISli6b': \"VISli\",\n",
    "    ### Visual primary\n",
    "    'VISp1': \"VISp\",\n",
    "    'VISp2/3': \"VISp\",\n",
    "    'VISp4': \"VISp\",\n",
    "    'VISp5': \"VISp\",\n",
    "    'VISp6a': \"VISp\",\n",
    "    'VISp6b': \"VISp\",\n",
    "    ### Visual posteromedial\n",
    "    'VISpm1': \"VISpm\",\n",
    "    'VISpm2/3': \"VISpm\",\n",
    "    'VISpm4': \"VISpm\",\n",
    "    'VISpm5': \"VISpm\",\n",
    "    'VISpm6a': \"VISpm\",\n",
    "    'VISpm6b': \"VISpm\",\n",
    "    ### TEa\n",
    "    'TEa1': \"TEa\",\n",
    "    'TEa2/3': \"TEa\",\n",
    "    'TEa4': \"TEa\",\n",
    "    'TEa5': \"TEa\",\n",
    "    'TEa6a': \"TEa\",\n",
    "    'TEa6b': \"TEa\",\n",
    "}\n",
    "\n",
    "# Create the gradient colors for the infected areas\n",
    "infected_colors = {}\n",
    "for base_area, base_color in large_actors.items():\n",
    "    num_shades = len([key for key in infected_areas if infected_areas[key] == base_area])\n",
    "    shades = generate_shades(base_color, num_shades)\n",
    "    for area in [key for key in infected_areas if infected_areas[key] == base_area]:\n",
    "        infected_colors[area] = shades.pop(0)\n",
    "\n",
    "#import ace_tools as tools; tools.display_dataframe_to_user(name=\"Infected Areas Colors\", dataframe=pd.DataFrame.from_dict(infected_colors, orient='index', columns=['Color']))\n",
    "\n",
    "infected_colors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unimportant_areas = [\n",
    "    'APN',\n",
    "    ###\n",
    "    'CA1',\n",
    "    'CA3',\n",
    "    'DG-mo',\n",
    "    'DG-po',\n",
    "    'DG-sg',\n",
    "    ### Ectorhinal\n",
    "    'ECT5',\n",
    "    'ECT6a',\n",
    "    ### Entorhinal\n",
    "    'ENTl5',\n",
    "    ###\n",
    "    'LP',\n",
    "    'MB',\n",
    "    'MGd',\n",
    "    'MGv',\n",
    "    'MRN',\n",
    "    'ND',\n",
    "    'PAG',\n",
    "    ###\n",
    "    'PERI6a',\n",
    "    'PERI6b',\n",
    "    ###\n",
    "    'POL',\n",
    "    ###\n",
    "    'PoT',\n",
    "    ###\n",
    "    'SCig',\n",
    "    'SCop',\n",
    "    'SCsg',\n",
    "    'SCzo',\n",
    "    'SGN',\n",
    "    ### Temporal association\n",
    "    'TEa1',\n",
    "    'TEa2/3',\n",
    "    'TEa4',\n",
    "    'TEa5',\n",
    "    'TEa6a',\n",
    "    'TEa6b',\n",
    "    ###\n",
    "    'alv',\n",
    "    'ar',\n",
    "    'bsc',\n",
    "    'cing',\n",
    "    'dhc',\n",
    "    'ec',\n",
    "    'fiber tracts',\n",
    "    'fp',\n",
    "    'or',\n",
    "    'scwm'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import brainrender\n",
    "# Initialize brainrender scene\n",
    "brainrender.settings.BACKGROUND_COLOR = [\n",
    "    0.10,\n",
    "    0.10,\n",
    "    0.10,\n",
    "]  # change rendering background color\n",
    "brainrender.settings.WHOLE_SCREEN = (\n",
    "    True  # make the rendering window be smaller\n",
    ")\n",
    "brainrender.settings.OFFSCREEN = False\n",
    "brainrender.settings.SHOW_AXES = False # turn off the axes display\n",
    "brainrender.settings.ROOT_ALPHA= (0.1)\n",
    "brainrender.settings.ROOT_COLOR = \"white\"\n",
    "brainrender.settings.DEFAULT_ATLAS = \"allen_mouse_10um\"\n",
    "brainrender.settings.SHADER_STYLE = \"cartoon\"\n",
    "brainrender.settings.LW = 0\n",
    "\n",
    "tab20 = plt.colormaps[\"tab20\"]\n",
    "\n",
    "\n",
    "\n",
    "# Create a brainrender scene with the custom plotter\n",
    "#scene = Scene(plotter_class=CustomPlotter)\n",
    "scene = Scene()\n",
    "\n",
    "large_actors = {\n",
    "    \"AUDpo\" : \"brown\",\n",
    "    \"VISp\" : \"blue\",\n",
    "    \"VISpl\" : \"lightgreen\",\n",
    "    \"VISl\" : \"mediumspringgreen\",\n",
    "    \"VISal\" : \"lime\",\n",
    "    \"VISpm\" : \"deepskyblue\",\n",
    "    \"VISli\" : \"cyan\",\n",
    "    \"RSP\" : \"deeppink\",\n",
    "    \"TEa\" : \"gold\",\n",
    "    'TH' : \"blueviolet\",\n",
    "    \"AUDd\" : \"yellow\",\n",
    "    \"AUDv\" : \"sandybrown\",\n",
    "    \"AUDp\" : \"orange\",\n",
    "}\n",
    "\n",
    "large_non_cortical_actors = [\n",
    "    \"HPF\",\n",
    "    \"ENT\",\n",
    "    \"PERI\",\n",
    "    \"ECT\",\n",
    "    \"BS\",\n",
    "    \"fiber tracts\",\n",
    "    \"OLF\",\n",
    "    \"CTXsp\"\n",
    "]\n",
    "all_actors = ara_barcode_spots[\"area_acronym\"].unique().astype(str)\n",
    "all_actors = all_actors.tolist()\n",
    "all_actors.remove(\"root\")\n",
    "brainreg_positions1 = [\n",
    "    np.array([8621.842 , 397.942 , 5706.5796], dtype=\"float32\"),\n",
    "    np.array([9575.921 , 214.3228, 5678.3687], dtype=\"float32\")\n",
    "]\n",
    "normal_vectors1 = [(-1.8919415, -0.12186934, 0.03463937), (1.8919415, 0.12186943, -0.03463934)]\n",
    "\n",
    "atlas = BrainGlobeAtlas(\"allen_mouse_10um\", check_latest=False)\n",
    "\n",
    "# Add infected areas\n",
    "infected_actors_list = []\n",
    "for i, actor in enumerate(infected_colors.items()):\n",
    "    #print(actor[0])\n",
    "    #print(added_actor._mesh)\n",
    "    added_actor = scene.add_brain_region(actor[0], alpha=0.07, color= actor[1], hemisphere=\"left\", silhouette=False)\n",
    "    #scene.add_silhouette(added_actor, lw=0.00001, color=actor[1])\n",
    "\n",
    "\n",
    "    infected_actors_list.append(added_actor)\n",
    "\n",
    "large_actors_list = []\n",
    "for i, actor in enumerate(large_actors.items()):\n",
    "    added_actor = scene.add_brain_region(actor[0], alpha=0.001, color= actor[1])# hemisphere=\"left\")\n",
    "    #print(actor[0])\n",
    "    #print(added_actor._mesh)\n",
    "    scene.add_silhouette(added_actor, lw=1, color=actor[1])\n",
    "    #scene.add_label(added_actor, actor,color= tab20(i % 20)[:3])\n",
    "    large_actors_list.append(added_actor)\n",
    "\n",
    "large_non_cortical_actors_list = []\n",
    "for i, actor in enumerate(large_non_cortical_actors):\n",
    "    added_actor = scene.add_brain_region(actor, alpha=0.05, color= \"grey\",)# hemisphere=\"left\")\n",
    "    #print(actor)\n",
    "    #print(added_actor._mesh)\n",
    "    scene.add_silhouette(added_actor, lw=0.0001, color=\"grey\")\n",
    "    #scene.add_label(added_actor, actor,color= tab20(i % 20)[:3])\n",
    "    large_non_cortical_actors_list.append(added_actor)\n",
    "\n",
    "selected_barcodes = [\"AGACTATGCTAAGC\", \"TTAATACGGGCTTT\", \"TACCATTAAGGCTG\"]  # Replace with actual barcodes\n",
    "render_selected_barcodes(20) #selected_barcodes)\n",
    "plane = Plane(pos=brainreg_positions1[0], s=(10000,5000), normal=normal_vectors1[1]) \n",
    "plane2 = Plane(pos=brainreg_positions1[1], s=(10000,5000), normal=normal_vectors1[0])\n",
    "scene.slice(plane, actors=infected_actors_list+large_actors_list+large_non_cortical_actors_list, close_actors=True)\n",
    "scene.slice(plane2, actors=infected_actors_list+large_actors_list+large_non_cortical_actors_list, close_actors=True)\n",
    "\n",
    "\n",
    "# Initialize a list to store camera information\n",
    "camera_info = []\n",
    "\n",
    "# Create a function to print the camera position, focal point, distance, and zoom\n",
    "def print_camera_info(event):\n",
    "    cam = scene.plotter.camera\n",
    "    cam_pos = cam.GetPosition()\n",
    "    focal_point = cam.GetFocalPoint()\n",
    "    distance = cam.GetDistance()\n",
    "    zoom = scene.plotter.camera.GetParallelScale() if scene.plotter.camera.GetParallelProjection() else scene.plotter.camera.GetViewAngle()\n",
    "    view_up = cam.GetViewUp()\n",
    "    info = {\n",
    "        \"position_x\": cam_pos[0],\n",
    "        \"position_y\": cam_pos[1],\n",
    "        \"position_z\": cam_pos[2],\n",
    "        \"focal_point_x\": focal_point[0],\n",
    "        \"focal_point_y\": focal_point[1],\n",
    "        \"focal_point_z\": focal_point[2],\n",
    "        \"distance\": distance,\n",
    "        \"zoom\": zoom,\n",
    "        \"view_up_x\": view_up[0],\n",
    "        \"view_up_y\": view_up[1],\n",
    "        \"view_up_z\": view_up[2]\n",
    "    }\n",
    "    \n",
    "    # Store the information in the list\n",
    "    camera_info.append(info)\n",
    "    \n",
    "    # Print all information in one line\n",
    "    print(f\"Position: {cam_pos}, Focal Point: {focal_point}, Distance: {distance}, Zoom: {zoom}\")\n",
    "\n",
    "# Add a callback to the plotter to print the camera information\n",
    "scene.plotter.add_callback('RightButtonPress', print_camera_info)\n",
    "\n",
    "custom_camera={\n",
    "    \"pos\": (4000.692883, -1007.944676, -8000.266488),\n",
    "    \"viewup\": ( 0.334511,  -0.941771,     0.0342),\n",
    "    \"clipping_range\": (31983, 76783),\n",
    "    \"focal_point\": (15858.069514,    4644.458311,\t-7535.302423),\n",
    "    \"distance\": 36264.153611\n",
    "    }\n",
    "root_actor = scene.get_actors('root')[0]\n",
    "root_actor.opacity(0)\n",
    "# Render the scene with the interactive GUI\n",
    "scene.render(camera=custom_camera, interactive=True) #\n",
    "\n",
    "\n",
    "# Convert the list of camera information to a DataFrame\n",
    "camera_df = pd.DataFrame(camera_info)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"Stored Camera Information DataFrame:\")\n",
    "print(camera_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_camera_df = camera_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Good renderer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import brainrender\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from brainrender import Scene, Animation\n",
    "from vedo import Plane\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "brainrender.settings.BACKGROUND_COLOR = [0.10, 0.10, 0.10]\n",
    "brainrender.settings.WHOLE_SCREEN = True\n",
    "brainrender.settings.OFFSCREEN = True\n",
    "brainrender.settings.SHOW_AXES = False\n",
    "brainrender.settings.ROOT_ALPHA = 0.1\n",
    "brainrender.settings.ROOT_COLOR = \"white\"\n",
    "brainrender.settings.DEFAULT_ATLAS = \"allen_mouse_25um\"\n",
    "brainrender.settings.SHADER_STYLE = \"cartoon\"\n",
    "brainrender.settings.LW = 0\n",
    "\n",
    "tab20 = plt.colormaps[\"tab20\"]\n",
    "\n",
    "# Create a brainrender scene\n",
    "scene = Scene()\n",
    "\n",
    "large_actors = {\n",
    "    \"AUDpo\": \"brown\",\n",
    "    \"VISp\": \"blue\",\n",
    "    \"VISpl\": \"lightgreen\",\n",
    "    \"VISl\": \"mediumspringgreen\",\n",
    "    \"VISal\": \"lime\",\n",
    "    \"VISpm\": \"deepskyblue\",\n",
    "    \"VISli\": \"cyan\",\n",
    "    \"RSP\": \"deeppink\",\n",
    "    \"TEa\": \"gold\",\n",
    "    'TH': \"blueviolet\",\n",
    "    \"AUDd\": \"yellow\",\n",
    "    \"AUDv\": \"sandybrown\",\n",
    "    \"AUDp\": \"orange\",\n",
    "}\n",
    "\n",
    "large_non_cortical_actors = [\n",
    "    \"HPF\",\n",
    "    \"ENT\",\n",
    "    \"PERI\",\n",
    "    \"ECT\",\n",
    "    \"BS\",\n",
    "    \"fiber tracts\",\n",
    "    \"OLF\",\n",
    "    \"CTXsp\"\n",
    "]\n",
    "\n",
    "all_actors = [\"root\"]  # Dummy data to avoid undefined variable error\n",
    "brainreg_positions1 = [\n",
    "    np.array([8621.842, 397.942, 5706.5796], dtype=\"float32\"),\n",
    "    np.array([9575.921, 214.3228, 5678.3687], dtype=\"float32\")\n",
    "]\n",
    "normal_vectors1 = [(-1.8919415, -0.12186934, 0.03463937), (1.8919415, 0.12186943, -0.03463934)]\n",
    "\n",
    "atlas = BrainGlobeAtlas(\"allen_mouse_10um\", check_latest=False)\n",
    "\n",
    "\n",
    "# Initialize a list to store camera information\n",
    "camera_info = []\n",
    "\n",
    "# Create a function to print the camera position, focal point, distance, and zoom\n",
    "def print_camera_info(event):\n",
    "    cam = scene.plotter.camera\n",
    "    cam_pos = cam.GetPosition()\n",
    "    focal_point = cam.GetFocalPoint()\n",
    "    distance = cam.GetDistance()\n",
    "    zoom = scene.plotter.camera.GetParallelScale() if scene.plotter.camera.GetParallelProjection() else scene.plotter.camera.GetViewAngle()\n",
    "    \n",
    "    info = {\n",
    "        \"position_x\": cam_pos[0],\n",
    "        \"position_y\": cam_pos[1],\n",
    "        \"position_z\": cam_pos[2],\n",
    "        \"focal_point_x\": focal_point[0],\n",
    "        \"focal_point_y\": focal_point[1],\n",
    "        \"focal_point_z\": focal_point[2],\n",
    "        \"distance\": distance,\n",
    "        \"zoom\": zoom\n",
    "    }\n",
    "    \n",
    "    # Store the information in the list\n",
    "    camera_info.append(info)\n",
    "    \n",
    "    # Print all information in one line\n",
    "    print(f\"Position: {cam_pos}, Focal Point: {focal_point}, Distance: {distance}, Zoom: {zoom}\")\n",
    "\n",
    "# Add a callback to the plotter to print the camera information\n",
    "scene.plotter.add_callback('keypress', print_camera_info)\n",
    "\n",
    "# Create video maker\n",
    "vmaker = Animation(scene, Path.cwd(), \"brainrender_video_highqual\")\n",
    "\n",
    "# Define callback function to show sliced large actors and large non-cortical actors\n",
    "def show_sliced_large_actors(scene, frame, total_frames):\n",
    "    # Add large actors\n",
    "    large_actors_list = []\n",
    "    for i, actor in enumerate(large_actors.items()):\n",
    "        added_actor = scene.add_brain_region(actor[0], alpha=0.001, color=actor[1])\n",
    "        scene.add_silhouette(added_actor, lw=1, color=actor[1])\n",
    "        large_actors_list.append(added_actor)\n",
    "\n",
    "    # Add large non-cortical actors\n",
    "    large_non_cortical_actors_list = []\n",
    "    for i, actor in enumerate(large_non_cortical_actors):\n",
    "        added_actor = scene.add_brain_region(actor, alpha=0.05, color=\"grey\")\n",
    "        scene.add_silhouette(added_actor, lw=0.0001, color=\"grey\")\n",
    "        large_non_cortical_actors_list.append(added_actor)\n",
    "    plane = Plane(pos=brainreg_positions1[0], s=(10000, 5000), normal=normal_vectors1[1])\n",
    "    plane2 = Plane(pos=brainreg_positions1[1], s=(10000, 5000), normal=normal_vectors1[0])\n",
    "    scene.slice(plane, actors=large_actors_list + large_non_cortical_actors_list, close_actors=True)\n",
    "    scene.slice(plane2, actors=large_actors_list + large_non_cortical_actors_list, close_actors=True)\n",
    "\n",
    "# Define callback function to show sliced infected actors\n",
    "def show_sliced_infected_actors(scene, frame, total_frames):\n",
    "    print(\"Showing sliced infected actors\")\n",
    "    infected_actors_list = []\n",
    "    for i, actor in enumerate(infected_colors.items()):\n",
    "        #print(actor[0])\n",
    "        added_actor = scene.add_brain_region(actor[0], alpha=0.07, color=actor[1], hemisphere=\"left\", silhouette=False)\n",
    "        infected_actors_list.append(added_actor)\n",
    "    plane = Plane(pos=brainreg_positions1[0], s=(10000, 5000), normal=normal_vectors1[1])\n",
    "    plane2 = Plane(pos=brainreg_positions1[1], s=(10000, 5000), normal=normal_vectors1[0])\n",
    "    scene.slice(plane, actors=infected_actors_list, close_actors=True)\n",
    "    scene.slice(plane2, actors=infected_actors_list, close_actors=True)\n",
    "\n",
    "# Define the render_selected_barcodes function without tqdm\n",
    "def render_selected_barcodes(selected_barcodes=None):\n",
    "    if selected_barcodes is None:\n",
    "        # Get all barcodes\n",
    "        selected_barcodes = common_barcodes\n",
    "    elif type(selected_barcodes) == int:\n",
    "        selected_barcodes = set(itertools.islice(common_barcodes, selected_barcodes))\n",
    "    unique_barcodes = list(set(selected_barcodes) & set(common_barcodes))\n",
    "    colors = get_cycled_colors(len(unique_barcodes))\n",
    "    barcode_to_color = dict(zip(unique_barcodes, colors))\n",
    "\n",
    "    # Group cells by barcode and color\n",
    "    for barcode in unique_barcodes:  # Removed tqdm for debugging\n",
    "        # Get points for current barcode\n",
    "        rabies_cells = read_in_BrainJ_cells(\n",
    "            ara_starters[(ara_starters[\"starter\"] == False) & (ara_starters[\"main_barcode\"] == barcode)],\n",
    "            [],\n",
    "            [],\n",
    "            [\"outside\"]\n",
    "        )\n",
    "        \n",
    "        starter_cells = read_in_BrainJ_cells(\n",
    "            ara_starters[(ara_starters[\"starter\"] == True) & (ara_starters[\"main_barcode\"] == barcode)],\n",
    "            [],\n",
    "            [],\n",
    "            [\"outside\"]\n",
    "        )\n",
    "        \n",
    "        rabies_spots = read_in_BrainJ_cells(\n",
    "            ara_barcode_spots[ara_barcode_spots[\"barcode\"] == barcode],\n",
    "            [],\n",
    "            [],\n",
    "            [\"outside\"]\n",
    "        )\n",
    "\n",
    "        color = barcode_to_color[barcode]\n",
    "\n",
    "        if rabies_cells.size > 0:\n",
    "            scene.add(Points(\n",
    "                rabies_cells,\n",
    "                name=f\"rabies_cells_{barcode}\",\n",
    "                colors=color,\n",
    "                alpha=0.2,\n",
    "                radius=10\n",
    "            ))\n",
    "        if starter_cells.size > 0:\n",
    "            scene.add(Points(\n",
    "                starter_cells,\n",
    "                name=f\"starter_cells_{barcode}\",\n",
    "                colors=color,\n",
    "                alpha=0.4,\n",
    "                radius=20\n",
    "            ))\n",
    "        if rabies_spots.size > 0:\n",
    "            scene.add(Points(\n",
    "                rabies_spots,\n",
    "                name=f\"rabies_spots_{barcode}\",\n",
    "                colors=color,\n",
    "                alpha=1,\n",
    "                radius=2\n",
    "            ))\n",
    "\n",
    "# Prepare common barcodes and data for rendering\n",
    "data_path = Path(\"C:/Microscope_images/processed/becalia_rabies_barseq/BRAC8498.3e/ara_spots\")\n",
    "ara_barcode_spots = pd.read_pickle(data_path / \"ara_barcode_spots.pkl\")\n",
    "ara_starters = pd.read_pickle(data_path / \"ara_starter_cells.pkl\")\n",
    "\n",
    "# Define read_in_BrainJ_cells and get_cycled_colors functions\n",
    "def read_in_BrainJ_cells(cells, regions, acronyms, not_in=None):\n",
    "    if len(regions) > 0:\n",
    "        cells = cells[cells['area_id'].isin(regions)]\n",
    "    if len(acronyms) > 0:\n",
    "        cells = cells[cells['area_acronym'].isin(acronyms)]\n",
    "    if not_in is not None:\n",
    "        cells = cells[~cells['area_acronym'].isin(not_in)]\n",
    "    Z = cells['ara_z'].tolist()\n",
    "    Y = cells['ara_y'].tolist()\n",
    "    X = cells['ara_x'].tolist()\n",
    "    \n",
    "    AtlasRes = 1000\n",
    "    X = [element * AtlasRes for element in X]\n",
    "    Y = [element * AtlasRes for element in Y]\n",
    "    Z = [element * AtlasRes for element in Z]\n",
    "    \n",
    "    if len(X) == 0:\n",
    "        return np.empty((0, 3))\n",
    "    \n",
    "    pts = [[x, y, z] for x, y, z in zip(X, Y, Z)]\n",
    "    return np.vstack(pts)\n",
    "\n",
    "def get_cycled_colors(n):\n",
    "    colors = list(mcolors.CSS4_COLORS.keys())\n",
    "    random.shuffle(colors)\n",
    "    return [colors[i % len(colors)] for i in range(n)]\n",
    "\n",
    "# Get unique barcodes present in both DataFrames\n",
    "common_barcodes = list(set(ara_barcode_spots['barcode'].unique()) & set(ara_starters['main_barcode'].unique()))\n",
    "#test_limit = 50\n",
    "#common_barcodes = common_barcodes[:test_limit]\n",
    "\n",
    "# Filter DataFrames to only include common barcodes\n",
    "ara_barcode_spots = ara_barcode_spots[ara_barcode_spots['barcode'].isin(common_barcodes)]\n",
    "ara_starters = ara_starters[ara_starters['main_barcode'].isin(common_barcodes)]\n",
    "\n",
    "\n",
    "# Keyframe 0: Start zoomed out from an angle\n",
    "vmaker.add_keyframe(\n",
    "    0,\n",
    "    camera={\n",
    "    \"pos\": (-163510.45445820506, -211818.18624394896, 107045.79069077772),\n",
    "    \"viewup\": (0, -1, 0),\n",
    "    \"clipping_range\": (31983, 76783),\n",
    "    \"focal_point\": (7829.739799214466, 4296.026746533125, -5694.49796940642),\n",
    "    \"distance\": 297948.29738034646\n",
    "    },\n",
    "    zoom=1\n",
    ")\n",
    "\n",
    "# Keyframe 1: Move in closer to the brain\n",
    "vmaker.add_keyframe(\n",
    "    10,\n",
    "    camera={\n",
    "    \"pos\": (-65155.224930,\t-73343.886028,\t37210.135701),\n",
    "    \"viewup\": (0, -1, 0),\n",
    "    \"clipping_range\": (31983, 76783),\n",
    "    \"focal_point\": (7829.739799,\t4296.026747,\t-5694.497969),\n",
    "    \"distance\": 114871.966652\n",
    "    },\n",
    "    zoom=1\n",
    ")\n",
    "\n",
    "# Keyframe 2: Move to a frontal position\n",
    "vmaker.add_keyframe(\n",
    "    20,\n",
    "    camera={\n",
    "    \"pos\": (-20956.499012,\t1598.608394,\t-5645.557678),\n",
    "    \"viewup\": (0, -1, 0),\n",
    "    \"clipping_range\": (31983, 76783),\n",
    "    \"focal_point\": (7834.890271,\t4165.833307,\t-5636.436126),\n",
    "    \"distance\": 14842.230469\n",
    "    },\n",
    "    zoom=1\n",
    ")\n",
    "\n",
    "# Keyframe 3: Hold that position\n",
    "vmaker.add_keyframe(\n",
    "    22,\n",
    "    camera={\n",
    "    \"pos\": (-20956.499012,\t1598.608394,\t-5645.557678),\n",
    "    \"viewup\": (0, -1, 0),\n",
    "    \"clipping_range\": (31983, 76783),\n",
    "    \"focal_point\": (7834.890271,\t4165.833307,\t-5636.436126),\n",
    "    \"distance\": 14842.230469\n",
    "    },\n",
    "    zoom=1\n",
    ")\n",
    "\n",
    "# Keyframe 3: Show sliced large actors and large non-cortical actors\n",
    "vmaker.add_keyframe(\n",
    "    23,\n",
    "    camera={\n",
    "    \"pos\": (-20956.499012,\t1598.608394,\t-5645.557678),\n",
    "    \"viewup\": (0, -1, 0),\n",
    "    \"clipping_range\": (31983, 76783),\n",
    "    \"focal_point\": (7834.890271,\t4165.833307,\t-5636.436126),\n",
    "    \"distance\": 14842.230469\n",
    "    },\n",
    "    zoom=1,\n",
    "    callback=show_sliced_large_actors\n",
    "    )\n",
    "\n",
    "# Keyframe 4: Show sliced infected actors\n",
    "vmaker.add_keyframe(\n",
    "    30,\n",
    "    camera={\n",
    "    \"pos\": (-20956.499012,\t1598.608394,\t-5645.557678),\n",
    "    \"viewup\": (0, -1, 0),\n",
    "    \"clipping_range\": (31983, 76783),\n",
    "    \"focal_point\": (7834.890271,\t4165.833307,\t-5636.436126),\n",
    "    \"distance\": 14842.230469\n",
    "    },\n",
    "    zoom=1,\n",
    "    callback=show_sliced_infected_actors\n",
    "    )\n",
    "\n",
    "# Keyframe 3: Hold that position\n",
    "vmaker.add_keyframe(\n",
    "    60,\n",
    "    camera={\n",
    "    \"pos\": (-20956.499012,\t1598.608394,\t-5645.557678),\n",
    "    \"viewup\": (0, -1, 0),\n",
    "    \"clipping_range\": (31983, 76783),\n",
    "    \"focal_point\": (7834.890271,\t4165.833307,\t-5636.436126),\n",
    "    \"distance\": 14842.230469\n",
    "    },\n",
    "    zoom=1\n",
    ")\n",
    "\n",
    "# Keyframe 3: Zoom out from frontal\n",
    "vmaker.add_keyframe(\n",
    "    70,\n",
    "    camera={\n",
    "    \"pos\": (-87026.182778,\t407.159312,\t-5649.790989),\n",
    "    \"viewup\": (0, -1, 0),\n",
    "    \"clipping_range\": (31983, 76783),\n",
    "    \"focal_point\": (7834.890271,\t4165.833307,\t-5636.43612),\n",
    "    \"distance\": 64935.509630\n",
    "    },\n",
    "    zoom=1\n",
    ")\n",
    "\n",
    "# Keyframe 4: Move to a upper position\n",
    "vmaker.add_keyframe(\n",
    "    75,\n",
    "    camera={\n",
    "    \"pos\": (14195.096893212758, -109809.87667053597, -3203.3762570010786),\n",
    "    \"viewup\": (0.997618,   0.068551,  -0.007656),\n",
    "    \"clipping_range\": (31983, 76783),\n",
    "    \"focal_point\": (6305.223994013311, 4770.690515059968, -5350.991573444866),\n",
    "    \"distance\": 114871.96665194607\n",
    "    },\n",
    "    zoom=1\n",
    ")\n",
    "\n",
    "\n",
    "# Keyframe 4: Zoom into upper position\n",
    "vmaker.add_keyframe(\n",
    "    80,\n",
    "    camera={\n",
    "    \"pos\": (14195.096893212758, -30809.87667053597, -3203.3762570010786),\n",
    "    \"viewup\": (0.997618,   0.068551,  -0.007656),\n",
    "    \"clipping_range\": (31983, 76783),\n",
    "    \"focal_point\": (6305.223994013311, 4770.690515059968, -5350.991573444866),\n",
    "    \"distance\": 114871.96665194607\n",
    "    },\n",
    "    zoom=1\n",
    ")\n",
    "\n",
    "# Keyframe 4: Hold upper position\n",
    "vmaker.add_keyframe(\n",
    "    140,\n",
    "    camera={\n",
    "    \"pos\": (14195.096893212758, -30809.87667053597, -3203.3762570010786),\n",
    "    \"viewup\": (0.997618,   0.068551,  -0.007656),\n",
    "    \"clipping_range\": (31983, 76783),\n",
    "    \"focal_point\": (6305.223994013311, 4770.690515059968, -5350.991573444866),\n",
    "    \"distance\": 114871.96665194607\n",
    "    },\n",
    "    zoom=1\n",
    ")\n",
    "\n",
    "# Keyframe 5: Move to a frontal position\n",
    "vmaker.add_keyframe(\n",
    "    145,\n",
    "    camera={\n",
    "    \"pos\": (-38006.226065,\t-6802.751214,\t-4756.497002),\n",
    "    \"viewup\": (0, -1, 0),\n",
    "    \"clipping_range\": (31983, 76783),\n",
    "    \"focal_point\": (6302.300431,\t4066.227106,\t-5476.308856),\n",
    "    \"distance\": 94935.509630\n",
    "    },\n",
    "    zoom=1\n",
    ")\n",
    "\n",
    "# Define a callback function to remove the root brain mesh from the scene\n",
    "def remove_root_brain(scene, frame, total_frames):\n",
    "    root_actor = scene.get_actors('root')[0]\n",
    "    scene.remove(root_actor)\n",
    "    print(\"Root brain mesh removed from the scene\")\n",
    "\n",
    "# Keyframe 6: Remove root\n",
    "vmaker.add_keyframe(\n",
    "    150,\n",
    "    camera={\n",
    "    \"pos\": (-38006.226065,\t-6802.751214,\t-4756.497002),\n",
    "    \"viewup\": (0, -1, 0),\n",
    "    \"clipping_range\": (31983, 76783),\n",
    "    \"focal_point\": (6302.300431,\t4066.227106,\t-5476.308856),\n",
    "    \"distance\": 94935.509630\n",
    "    },\n",
    "    zoom=1,\n",
    "    callback=remove_root_brain\n",
    ")\n",
    "\n",
    "\n",
    "# Keyframe 5: Zoom into infected area\n",
    "vmaker.add_keyframe(\n",
    "    160,\n",
    "    camera={\n",
    "    \"pos\": (-2553.692883, -2047.944676, -10000.266488),\n",
    "    \"viewup\": ( 0.334511,  -0.941771,     0.0342),\n",
    "    \"clipping_range\": (31983, 76783),\n",
    "    \"focal_point\": (15858.069514,    4644.458311,\t-7535.302423),\n",
    "    \"distance\": 36264.153611\n",
    "    },\n",
    "    zoom=1\n",
    ")\n",
    "\n",
    "\n",
    "# Define the callback function to add barcodes incrementally\n",
    "def add_barcodes_incrementally(scene, frame, total_frames):\n",
    "    global added_barcodes\n",
    "    # Calculate the number of barcodes to add based on the frame\n",
    "    if len(added_barcodes) < 30:\n",
    "        num_barcodes = 1  # First 10 barcodes: 1 per second\n",
    "    elif len(added_barcodes) < 250:\n",
    "        num_barcodes = 10  # Next 100 barcodes: 10 per second\n",
    "    else:\n",
    "        num_barcodes = 100  # Remaining barcodes: 100 per second\n",
    "    \n",
    "    # Determine the new barcodes to add\n",
    "    new_barcodes = list(itertools.islice(common_barcodes, len(added_barcodes), len(added_barcodes) + num_barcodes))\n",
    "    added_barcodes.extend(new_barcodes)\n",
    "    render_selected_barcodes(new_barcodes)\n",
    "    print(f\"Added barcodes: {new_barcodes}\")\n",
    "\n",
    "# Add keyframes for adding barcodes incrementally\n",
    "added_barcodes = []\n",
    "# Define the number of barcodes for each stage\n",
    "first_stage_barcodes = 30\n",
    "second_stage_barcodes = 250\n",
    "remaining_barcodes = len(common_barcodes) - (first_stage_barcodes + second_stage_barcodes)\n",
    "\n",
    "# Calculate the number of keyframes required for each stage\n",
    "first_stage_keyframes = first_stage_barcodes  # 1 barcode per keyframe\n",
    "second_stage_keyframes = second_stage_barcodes // 10  # 10 barcodes per keyframe\n",
    "remaining_stage_keyframes = (remaining_barcodes + 99) // 100  # 100 barcodes per keyframe, ceiling division\n",
    "\n",
    "# Total number of keyframes\n",
    "total_keyframes = 170 + first_stage_keyframes + second_stage_keyframes + remaining_stage_keyframes\n",
    "\n",
    "\n",
    "for frame in range(170, total_keyframes):\n",
    "    vmaker.add_keyframe(\n",
    "        frame,\n",
    "        camera={\n",
    "            \"pos\": (-2553.692883, -2047.944676, -10000.266488),\n",
    "            \"viewup\": ( 0.334511,  -0.941771,     0.0342),\n",
    "            \"clipping_range\": (31983, 76783),\n",
    "            \"focal_point\": (15858.069514,    4644.458311,\t-7535.302423),\n",
    "            \"distance\": 36264.153611\n",
    "        },\n",
    "        zoom=1,\n",
    "        callback=add_barcodes_incrementally\n",
    "        )\n",
    "\n",
    "\n",
    "# Keyframe 5: Zoom into infected area\n",
    "vmaker.add_keyframe(\n",
    "    total_keyframes + 10,\n",
    "    camera={\n",
    "    \"pos\": (4000.692883, -1007.944676, -8000.266488),\n",
    "    \"viewup\": ( 0.334511,  -0.941771,     0.0342),\n",
    "    \"clipping_range\": (31983, 76783),\n",
    "    \"focal_point\": (15858.069514,    4644.458311,\t-7535.302423),\n",
    "    \"distance\": 36264.153611\n",
    "    },\n",
    "    zoom=1\n",
    ")\n",
    "total_keyframes += 10\n",
    "\n",
    "# Keyframe 5: pan infected area\n",
    "vmaker.add_keyframe(\n",
    "    total_keyframes + 10,\n",
    "    camera={\n",
    "    \"pos\": (760.9075903071061, -6800.78538540021, -16825.953826529476),\n",
    "    \"viewup\": ( 0.629375,  -0.766265,   0.129328),\n",
    "    \"clipping_range\": (31983, 76783),\n",
    "    \"focal_point\": (25241.50034339267, 17832.986967211807, 9993.803901083016),\n",
    "    \"distance\": 43879.62586930941\n",
    "    },\n",
    "    zoom=1\n",
    ")\n",
    "total_keyframes += 10\n",
    "\n",
    "# Keyframe 5: pan infected area\n",
    "vmaker.add_keyframe(\n",
    "    total_keyframes + 10,\n",
    "    camera={\n",
    "    \"pos\": (4478.584446588466, -9169.56688087612, -29822.18279305565),\n",
    "    \"viewup\": ( 0.395164 , -0.850584 ,  0.346917),\n",
    "    \"clipping_range\": (31983, 76783),\n",
    "    \"focal_point\": (13951.842397583103, 14273.251159486239, 16865.089364689422),\n",
    "    \"distance\":  53094.347301864254\n",
    "    },\n",
    "    zoom=1\n",
    ")\n",
    "total_keyframes += 10\n",
    "\n",
    "# Keyframe 5: pan infected area\n",
    "vmaker.add_keyframe(\n",
    "    total_keyframes + 10,\n",
    "    camera={\n",
    "    \"pos\": (20845.138794959097, -6154.10581368232, -28893.475186677686),\n",
    "    \"viewup\": ( -0.053359 , -0.945052 ,  0.322537 ),\n",
    "    \"clipping_range\": (31983, 76783),\n",
    "    \"focal_point\": (-5167.558467034369, 10104.710745190683, 14442.424257913592),\n",
    "    \"distance\":  53094.347301863796\n",
    "    },\n",
    "    zoom=1\n",
    ")\n",
    "total_keyframes += 10\n",
    "\n",
    "# Keyframe 5: pan infected area\n",
    "vmaker.add_keyframe(\n",
    "    total_keyframes + 10,\n",
    "    camera={\n",
    "    \"pos\": (30474.199492520165, -4568.039851240409, -21612.45498009715),\n",
    "    \"viewup\": (-0.204645 , -0.972840 ,  0.108180  ),\n",
    "    \"clipping_range\": (31983, 76783),\n",
    "    \"focal_point\": (-13659.587309022345, 7701.088152535213, 5233.160602225766),\n",
    "    \"distance\":  53094.347301863796\n",
    "    },\n",
    "    zoom=1\n",
    ")\n",
    "total_keyframes += 10\n",
    "\n",
    "# Calculate the duration based on the total number of keyframes\n",
    "fps = 1 # Frame rate\n",
    "duration = total_keyframes  # Duration of the video\n",
    "print(f\"Total keyframes: {total_keyframes}, Duration: {duration}\")\n",
    "render_kwargs = {\n",
    "    \"width\": 1920,\n",
    "    \"height\": 1080,\n",
    "}\n",
    "vmaker.make_video(fps=1, duration=duration, render_kwargs=render_kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keyframe 3: Show sliced large actors and large non-cortical actors\n",
    "vmaker.add_keyframe(2, camera=\"frontal\", zoom=1, callback=show_sliced_large_actors)\n",
    "\n",
    "# Keyframe 4: Show sliced infected actors\n",
    "vmaker.add_keyframe(3, camera=\"frontal\", zoom=1, callback=show_sliced_infected_actors)\n",
    "\n",
    "# Keyframe 5: Move to a top camera view\n",
    "vmaker.add_keyframe(4, camera=\"top\", zoom=1)\n",
    "\n",
    "# Keyframe 7: Move to a frontal view\n",
    "vmaker.add_keyframe(6, camera=\"frontal\", zoom=1)\n",
    "\n",
    "# Add keyframes for adding barcodes incrementally\n",
    "added_barcodes = []\n",
    "# Define the number of barcodes for each stage\n",
    "first_stage_barcodes = 10\n",
    "second_stage_barcodes = 100\n",
    "remaining_barcodes = len(common_barcodes) - (first_stage_barcodes + second_stage_barcodes)\n",
    "\n",
    "# Calculate the number of keyframes required for each stage\n",
    "first_stage_keyframes = first_stage_barcodes  # 1 barcode per keyframe\n",
    "second_stage_keyframes = second_stage_barcodes // 10  # 10 barcodes per keyframe\n",
    "remaining_stage_keyframes = (remaining_barcodes + 99) // 100  # 100 barcodes per keyframe, ceiling division\n",
    "\n",
    "# Total number of keyframes\n",
    "total_keyframes = 70 + first_stage_keyframes + second_stage_keyframes + remaining_stage_keyframes\n",
    "\n",
    "# Calculate the duration based on the total number of keyframes\n",
    "fps = 10  # Frame rate\n",
    "duration = total_keyframes / fps  # Duration of the video\n",
    "print(f\"Total keyframes: {total_keyframes}, Duration: {duration}\")\n",
    "\n",
    "for frame in range(7, total_keyframes):\n",
    "    vmaker.add_keyframe(frame, camera=\"frontal\", zoom=1, callback=add_barcodes_incrementally)\n",
    "\n",
    "total_keyframes = 30\n",
    "# Calculate the duration based on the limited number of barcodes\n",
    "fps = 10  # Frame rate\n",
    "duration = total_keyframes + 7 / fps  # Duration of the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correcting the data manually to fit the columns\n",
    "corrected_data = [\n",
    "    [0, -163510.454458, -211818.186244, 107045.790691, 7829.739799, 4296.026747, -5694.497969, 297948.297381, 7.5],\n",
    "    [1, -163510.454458, -211818.186244, 107045.790691, 7829.739799, 4296.026747, -5694.497969, 297948.297381, 7.5],\n",
    "    [2, -65155.224930, -73343.886028, 37210.135701, 7829.739799, 4296.026747, -5694.497969, 114871.966652, 7.5],\n",
    "    [3, -65155.224930, -73343.886028, 37210.135701, 7829.739799, 4296.026747, -5694.497969, 114871.966652, 7.5],\n",
    "    [4, -56956.499012, 1598.608394, -5645.557678, 7834.890271, 4165.833307, -5636.436126, 64842.230469, 7.5],\n",
    "    [5, -56956.499012, 1598.608394, -5645.557678, 7834.890271, 4165.833307, -5636.436126, 64842.230469, 7.5],\n",
    "    [6, -87026.182778, 407.159312, -5649.790989, 7834.890271, 4165.833307, -5636.436126, 94935.509630, 7.5],\n",
    "    [7, -87026.182778, 407.159312, -5649.790989, 7834.890271, 4165.833307, -5636.436126, 94935.509630, 7.5],\n",
    "    [8, 15029.545571, -110462.637346, -3881.591874, 6302.300431, 4066.227106, -5476.308856, 114871.966652, 7.5],\n",
    "    [9, 15029.545571, -110462.637346, -3881.591874, 6302.300431, 4066.227106, -5476.308856, 114871.966652, 7.5],\n",
    "    [10, -88006.226065, -6802.751214, -4756.497002, 6302.300431, 4066.227106, -5476.308856, 94935.509630, 7.5],\n",
    "    [11, -88006.226065, -6802.751214, -4756.497002, 6302.300431, 4066.227106, -5476.308856, 94935.509630, 7.5],\n",
    "    [12, -29346.838229, -4781.464885, -10919.744495, 6508.258583, 2141.097121, -8434.151348, 36601.748666, 7.5],\n",
    "    [13, -29346.838229, -4781.464885, -10919.744495, 6508.258583, 2141.097121, -8434.151348, 36601.748666, 7.5]\n",
    "]\n",
    "\n",
    "# Define the columns\n",
    "columns = ['index', 'position_x', 'position_y', 'position_z', 'focal_point_x', 'focal_point_y', 'focal_point_z', 'distance', 'zoom']\n",
    "import pandas as pd\n",
    "# Create the dataframe\n",
    "df_corrected = pd.DataFrame(corrected_data, columns=columns)\n",
    "\n",
    "# Format float columns to 6 decimal places\n",
    "formatted_df_corrected = df_corrected.applymap(lambda x: f\"{x:.6f}\" if isinstance(x, float) else x)\n",
    "\n",
    "# Show the formatted dataframe\n",
    "formatted_df_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import brainrender\n",
    "import numpy as np\n",
    "from brainrender import Scene, Animation\n",
    "from vedo import Plane\n",
    "\n",
    "brainrender.settings.BACKGROUND_COLOR = [0.12, 0.12, 0.12]\n",
    "brainrender.settings.WHOLE_SCREEN = False\n",
    "brainrender.settings.SHOW_AXES = False\n",
    "brainrender.settings.ROOT_ALPHA = 0.5\n",
    "brainrender.settings.ROOT_COLOR = \"white\"\n",
    "brainrender.settings.DEFAULT_ATLAS = \"allen_mouse_25um\"\n",
    "brainrender.settings.SHADER_STYLE = \"cartoon\"\n",
    "brainrender.settings.LW = 0\n",
    "brainrender.settings.OFFSCREEN = True\n",
    "\n",
    "# Create a brainrender scene\n",
    "scene = Scene()\n",
    "\n",
    "# Adding brain regions as described\n",
    "large_actors = {\n",
    "    \"AUDpo\": \"brown\",\n",
    "    \"VISp\": \"blue\",\n",
    "    \"VISpl\": \"lightgreen\",\n",
    "    \"VISl\": \"mediumspringgreen\",\n",
    "    \"VISal\": \"lime\",\n",
    "    \"VISpm\": \"deepskyblue\",\n",
    "    \"VISli\": \"cyan\",\n",
    "    \"RSP\": \"deeppink\",\n",
    "    \"TEa\": \"gold\",\n",
    "    \"TH\": \"blueviolet\",\n",
    "    \"AUDd\": \"yellow\",\n",
    "    \"AUDv\": \"sandybrown\",\n",
    "    \"AUDp\": \"orange\",\n",
    "}\n",
    "\n",
    "large_non_cortical_actors = [\n",
    "    \"HPF\",\n",
    "    \"ENT\",\n",
    "    \"PERI\",\n",
    "    \"ECT\",\n",
    "    \"BS\",\n",
    "    \"fiber tracts\",\n",
    "    \"OLF\",\n",
    "    \"CTXsp\"\n",
    "]\n",
    "\n",
    "# Initially, do not add actors to the scene\n",
    "added_actors = []\n",
    "\n",
    "brainreg_positions1 = [\n",
    "    np.array([8621.842, 397.942, 5706.5796], dtype=\"float32\"),\n",
    "    np.array([9575.921, 214.3228, 5678.3687], dtype=\"float32\")\n",
    "]\n",
    "normal_vectors1 = [(-1.8919415, -0.12186934, 0.03463937), (1.8919415, 0.12186943, -0.03463934)]\n",
    "\n",
    "plane = Plane(pos=brainreg_positions1[0], s=(10000, 5000), normal=normal_vectors1[1])\n",
    "plane2 = Plane(pos=brainreg_positions1[1], s=(10000, 5000), normal=normal_vectors1[0])\n",
    "\n",
    "# Create video maker\n",
    "vmaker = Animation(scene, \"folder\", \"brainrender_video\")\n",
    "\n",
    "# Define callback function to show sliced actors\n",
    "def show_sliced_actors(scene, frame, total_frames):\n",
    "    global added_actors\n",
    "    for actor in large_actors.keys():\n",
    "        added_actor = scene.add_brain_region(actor, alpha=0.1, color=large_actors[actor])\n",
    "        added_actors.append(added_actor)\n",
    "    for actor in large_non_cortical_actors:\n",
    "        added_actor = scene.add_brain_region(actor, alpha=0.1, color=\"grey\")\n",
    "        added_actors.append(added_actor)\n",
    "    scene.slice(plane, actors=added_actors)\n",
    "    scene.slice(plane2, actors=added_actors, close_actors=True)\n",
    "\n",
    "# Define callback function to hide actors\n",
    "def hide_actors(scene, frame, total_frames):\n",
    "    global added_actors\n",
    "    for actor in added_actors:\n",
    "        scene.remove(actor)\n",
    "    added_actors = []\n",
    "\n",
    "# Keyframe 1: Initial state with only root visible\n",
    "vmaker.add_keyframe(0, camera=\"frontal\", zoom=1)\n",
    "\n",
    "# Keyframe 2: Show sliced brain regions using callback\n",
    "vmaker.add_keyframe(1, camera=\"frontal\", zoom=1, callback=show_sliced_actors)\n",
    "\n",
    "# Keyframe 3: Pan to a top view\n",
    "vmaker.add_keyframe(2, camera=\"top\", zoom=1)\n",
    "\n",
    "# Keyframe 4: Pan to a sagittal view\n",
    "vmaker.add_keyframe(3, camera=\"sagittal\", zoom=1)\n",
    "\n",
    "# Keyframe 5: Hide the actors\n",
    "vmaker.add_keyframe(4, camera=\"frontal\", zoom=1, callback=hide_actors)\n",
    "\n",
    "# Render the video\n",
    "vmaker.make_video(fps=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize brainrender scene\n",
    "scene = Scene()\n",
    "tab20 = plt.colormaps[\"tab20\"]\n",
    "\n",
    "folder_path = 'C:/Microscope_data/BRAC8498.3e/overviews/'\n",
    "# Create a list of all .tif files ending with .ome.tif_Coords.tif\n",
    "tif_files = glob.glob(f'{folder_path}/*.ome.tif_Coords.tif')\n",
    "#Order the files alphabetically\n",
    "tif_files.sort()\n",
    "# Select the first and last file\n",
    "first_slice = tif_files[0]\n",
    "last_slice = tif_files[-1]\n",
    "\n",
    "rotate = False  \n",
    "\n",
    "# Iterate over the list of files\n",
    "for i, file_path in enumerate(tif_files):\n",
    "\n",
    "    # Load the image\n",
    "    img = imageio.imread(file_path)  # Adjust this path\n",
    "\n",
    "    # img.shape is (3, height, width)\n",
    "    # Let's pick three points: top-left corner, top-right corner, and bottom-left corner of the image\n",
    "    p1 = np.array([img[0, 0, 0], img[1, 0, 0], img[2, 0, 0]])  # Top-left corner\n",
    "    p2 = np.array([img[0, 0, -1], img[1, 0, -1], img[2, 0, -1]])  # Top-right corner\n",
    "    p3 = np.array([img[0, -1, 0], img[1, -1, 0], img[2, -1, 0]])  # Bottom-left corner\n",
    "\n",
    "    #Let's find the central point of the image too\n",
    "    p4 = np.array(\n",
    "                [img[0, img.shape[1] // 2, img.shape[2] // 2],\n",
    "                 img[1, img.shape[1] // 2, img.shape[2] // 2],\n",
    "                 img[2, img.shape[1] // 2, img.shape[2] // 2]])\n",
    "\n",
    "    # Compute vectors\n",
    "    v1 = p2 - p1\n",
    "    v2 = p3 - p1\n",
    "\n",
    "    # Compute the normal vector to the plane defined by v1 and v2\n",
    "    normal_vector = np.cross(v1, v2)\n",
    "    normal_vector = normal_vector / np.linalg.norm(normal_vector)  # Normalize the vector\n",
    "    #normal_vector = (normal_vector[2], normal_vector[1], normal_vector[0])  # Adjust the order of the elements\n",
    "    brainreg_position = (p4[0] * 1000, p4[1] * 1000, p4[2] * 1000)\n",
    "\n",
    "    c = tab20(i % 20)[:3]\n",
    "\n",
    "    # Add the plane to the scene\n",
    "    plane = Plane(pos=brainreg_position, s=(10000, 5000), normal=tuple(normal_vector), c=c) #  \n",
    "    scene.add(plane)\n",
    "\n",
    "# Render the scene\n",
    "scene.render()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 1 2\n",
    "# straight down midline\n",
    "# 0 2 1\n",
    "# straight down midline but flipped direction\n",
    "# 1 0 2\n",
    "# flat across midline (brown up)\n",
    "# 1 2 0\n",
    "# correct plane, blue first\n",
    "# 2 0 1\n",
    "#crash\n",
    "# 2 1 0\n",
    "#correct plane, rotated 90 degrees, blue first\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import imageio\n",
    "from brainglobe_atlasapi import BrainGlobeAtlas\n",
    "\n",
    "folder_path = 'C:/Microscope_data/BRAC8498.3e/overviews/'\n",
    "# Create a list of all .tif files ending with .ome.tif_Coords.tif\n",
    "tif_files = glob.glob(f'{folder_path}/*.ome.tif_Coords.tif')\n",
    "\n",
    "# Iterate over the list of files\n",
    "for i, file_path in enumerate(tif_files):\n",
    "    test_path = file_path\n",
    "\n",
    "def get_unique_actors_from_tif(file_path):\n",
    "    \"\"\" Given a path to a .tif file, this function returns a list of unique actors in the image.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the .tif file\n",
    "\n",
    "    Returns:\n",
    "        list: List of unique actors in the image\n",
    "    \"\"\"\n",
    "    # Load the BrainGlobe Atlas\n",
    "    bg_atlas = BrainGlobeAtlas(\"allen_mouse_25um\", check_latest=False)\n",
    "    \n",
    "    # Load the image\n",
    "    img = imageio.imread(file_path)\n",
    "    \n",
    "    # Assume img.shape is (3, height, width)\n",
    "    height, width = img.shape[1], img.shape[2]\n",
    "    \n",
    "    # Calculate step sizes for the grid\n",
    "    step_x = 1\n",
    "    step_y = 1\n",
    "    \n",
    "    # Initialize an empty set for unique actors\n",
    "    unique_actors = set()\n",
    "    \n",
    "    # Sample points in a 100x100 grid\n",
    "    for i in range(0, height, step_y):\n",
    "        for j in range(0, width, step_x):\n",
    "            # Convert image coordinates to atlas coordinates\n",
    "            # Assume that the conversion to atlas coordinates is similar to brainreg_position calculation\n",
    "            x, y = j, i\n",
    "            coord = (img[2, i, j] * 1000, img[1, i, j] * 1000, img[0, i, j] * 1000)\n",
    "            # Query the atlas for the structure at this coordinate\n",
    "            try:\n",
    "                structure = bg_atlas.structure_from_coords(coord, microns=True, as_acronym=True,  hierarchy_lev=2)\n",
    "            except:\n",
    "                structure = None\n",
    "            # Add the result to the set of unique actors\n",
    "            if structure is not None:\n",
    "                unique_actors.add(structure)\n",
    "    \n",
    "    # Convert the set to a list to return\n",
    "    return list(unique_actors)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
